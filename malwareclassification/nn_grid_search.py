
import numpy as np


#选择neural network的最佳参数
#create_model 设置的是200，200这个网络
# use above code for grid search if you have enough RAM, modifying tune_batch_epochs() method and comment everything above
from sklearn.model_selection import GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam
import os
total_features = 25000  # total unique features

data = np.loadtxt(open("..//data//x_train01.csv","rb"),delimiter=",",skiprows=0)
labels = np.loadtxt(open("..//data//y_train01.csv","rb"),delimiter=",",skiprows=0)


def create_model(learn_rate=0.001,kernel_initializer='glorot_uniform',bias_initializer='zeros',dropout_rate=0.5):
    model = Sequential()

    model.add(Dense(units=200, activation="relu", input_dim=total_features,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer))
    model.add(Dropout(dropout_rate))  # add dropout

    model.add(Dense(units=200, activation="relu",kernel_initializer=kernel_initializer,bias_initializer=bias_initializer))
    model.add(Dropout(dropout_rate))

    model.add(Dense(2, activation="softmax",kernel_initializer=kernel_initializer,bias_initializer=bias_initializer))  # output layer, with softmax activation function and 2 neurons

    model.compile(loss="sparse_categorical_crossentropy",
                  optimizer=Adam(lr=learn_rate),
                  metrics=["accuracy"])
    # loss sparse categorical, Adam optimizer
    model.summary()
    return model


def tune_batch_epochs():

    model = KerasClassifier(build_fn=create_model, verbose=1)

    epochs = [5, 10, 15, 20]
    batch_size = [50, 100, 128, 200]
    #我们确定Adam
    #optimizer = [ 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']
    # optimizer=['SGD']
    learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]
    # momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]  # to work with SGD
    dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
    kernel_initializer = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']  # weight init
    bias_initializer=['Zeros']
    param_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate=learn_rate, kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,dropout_rate=dropout_rate)

    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)
    grid_result = grid.fit(data, labels)

    print("Best: ", grid_result.best_score_, "using", grid_result.best_params_)
    means = grid_result.cv_results_['mean_test_score']
    stds = grid_result.cv_results_['std_test_score']
    params = grid_result.cv_results_['params']
    for mean, stdev, param in zip(means, stds, params):
        print(mean, stdev, "with",  param)


tune_batch_epochs()

