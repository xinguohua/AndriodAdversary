from malwareclassification import models
from malwareclassification import neural_network as NN
import pandas as pd
import numpy as np


def train_DNN_models():

    total_features = 25000

    # neural net parameters
    units = [200, 200]
    dropout = 0.2  # dropout rate to avoid over fitting (Note that dropout alone is not efficient)
    epochs = 10  # set maximum epochs to 20. If callbacks are specified Keras will automatically stop the procedure
    batch_size = 150  # we found that the batch size of 150 fits better in our task
    learn_rate = 0.001  # specify the learning rate according to the optimizer used
    kernel_initializer = 'glorot_uniform'  # weight initialization
    bias_initializer = 'zeros'  # bias initialization
    activation_function = 'relu'  # activation function



    # init the neural net
    model = NN.generate_neural_network(total_features, units, dropout, learn_rate, kernel_initializer,
                                     bias_initializer, activation_function)
    """
    train the neural network with the given model, epochs, batch size, train data-labels.
    Specify verbosity level, validation data, callbacks and plots (if needed).
    Default parameters:
    verbose=0, validation=False, val_data=None, val_labels=None, callbacks=False, plot_history=False
    example:
    NN.train_neural_network(model, epochs, batch_size, data, labels, verbose=0,
                            validation=True, val_data=test_data, val_labels=test_labels,
                            callbacks=True, plot_history=True)
    This is the main training stage and thus we want to save the best models at the 'right time'. This is done
    setting the callback to True. Keras will seek for the minimum validation loss and it saves the model with
    the highest validation accuracy.
    """
    NN.train_neural_network(model, epochs, batch_size, data, labels, verbose=2,
                            validation=True, val_data=test_data, val_labels=test_labels,
                            callbacks=True, plot_history=True)


# def train_GNB_models():
#
#     model = GNB.train_gaussian_naive_bayes_classifier(data, labels, save=True)  # train Naive Bayes
#     GNB.evaluate_gaussian_naive_bayes_classifier(model, test_data, test_labels)  # test performance
#
# def train_MNB_models():
#     model = MNB.train_multi_naive_bayes_classifier(data, labels, save=True)
#     MNB.evaluate_multi_naive_bayes_classifier(model, test_data, test_labels)
#
#
# def train_BNB_models():
#      model = BNB.train_bernoulli_naive_bayes_classifier(data, labels, save=True)
#      BNB.evaluate_bernoulli_naive_bayes_classifier(model, test_data, test_labels)
#
# def train_CNB_models():
#     model = CNB.train_complement_naive_bayes_classifier(data, labels, save=True)
#     CNB.evaluate_complement_naive_bayes_classifier(model, test_data, test_labels)
#
# def train_DT_models():
#      model = DT.train_decision_tree_classifier(data, labels, save=True)
#      DT.evaluate_decision_tree_classifier(model, test_data, test_labels)
#
# def train_RF_models():
#
#     model = RF.train_random_forest_classifier(data, labels, save=True)
#     RF.evaluate_random_forest_classifier(model, test_data, test_labels)
#
# def train_KNN_models():
#     model = KNN.train_knn_classifier(data, labels, save=True)
#     KNN.evaluate_knn_classifier(model, test_data, test_labels)
#
# def train_LR_models():
#      model = LR.train_logistic_regression_classifier(data, labels, save=True)
#      LR.evaluate_logistic_regression_classifier(model, test_data, test_labels)
#
# def train_SVM_models():
#     model = SVM.train_svm_classifier(data, labels, save=True)
#     SVM.evaluate_svm_classifier(model, test_data, test_labels)


if __name__ == "__main__":


    # data = pd.read_csv('D:\\安全课程\\android detection\\Android-Malware-Detection-Adversarial-Examples-master\\drebin\\x_train.csv')
    # labels = pd.read_csv('D:\\安全课程\\android detection\\Android-Malware-Detection-Adversarial-Examples-master\\drebin\\y_train.csv')
    # test_data = pd.read_csv('D:\\安全课程\\android detection\\Android-Malware-Detection-Adversarial-Examples-master\\drebin\\x_test.csv')
    # test_labels = pd.read_csv('D:\\安全课程\\android detection\\Android-Malware-Detection-Adversarial-Examples-master\\drebin\\y_test.csv')
    data = pd.read_csv('D:\\data\\x_train01.csv')
    labels = pd.read_csv('D:\\data\\y_train01.csv')
    test_data = pd.read_csv('D:\\data\\x_test01.csv')
    test_labels = pd.read_csv('D:\\data\\y_test01.csv')

    # data = np.loadtxt(open("D:\\data\\x_train01.csv", "rb"), delimiter=",", skiprows=0, dtype=np.float32)
    # data=np.mat(data)
    # labels = np.loadtxt(open("D:\\data\\y_train01.csv", "rb"), delimiter=",", skiprows=0, dtype=np.float32)
    # labels=np.mat(labels)
    # test_data = np.loadtxt(open("D:\\data\\x_test01.csv", "rb"), delimiter=",", skiprows=0, dtype=np.float32)
    # test_labels = np.loadtxt(open("D:\\data\\y_test01.csv", "rb"), delimiter=",", skiprows=0, dtype=np.float32)
    # test_data = np.mat(test_data)
    # test_labels = np.mat(test_labels)

    # initialize sklearn models (classic machine learning)
    # GNB = models.GaussianNaiveBayes()
    # MNB = models.MultinomialNaiveBayes()
    # CNB = models.ComplementNaiveBayes()
    # BNB = models.BernoulliNaiveBayes()
    # DT = models.DecisionTree()
    # RF = models.RandomForest()
    # KNN = models.KNearestNeighbors()
    # LR = models.LogRegression()
    # SVM = models.SupportVectorMachine()



    train_DNN_models()





    #     for classic machine learning model, e.g., Naive Bayes, Decision Tree etc, first we fit the classifier and
    #     then we evaluate on the test. The best hyperparameters found from the grid search procedure are defined
    #     in the models.py helper script.

    # train_GNB_models()
    #
    # train_MNB_models()
    # train_CNB_models()
    # train_BNB_models()
    # train_DT_models()
    # train_RF_models()
    # train_KNN_models()
    # train_LR_models()
    # train_SVM_models()

